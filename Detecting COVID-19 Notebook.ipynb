{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting COVID-19 with Chest X Ray using PyTorch\n",
    "\n",
    "Image classification of Chest X Rays in one of three classes: Normal, Viral Pneumonia, COVID-19\n",
    "\n",
    "Dataset from [COVID-19 Radiography Dataset](https://www.kaggle.com/tawsifurrahman/covid19-radiography-database) on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a Python package that provides two high-level features:\n",
    "\n",
    "- Tensor computation (like NumPy) with strong GPU acceleration\n",
    "- Deep neural networks built on a tape-based autograd system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following libraries:\n",
    "- pyplot from matplotlib\n",
    "- Image from PIL : The Python Imaging Library adds image processing capabilities to your Python interpreter. This library provides extensive file format support, an efficient internal representation, and fairly powerful image processing capabilities. The core image library is designed for fast access to data stored in a few basic pixel formats. It should provide a solid foundation for a general image processing tool.\n",
    "\n",
    "- numpy\n",
    "- shutil : The shutil module offers a number of high-level operations on files and collections of files. In particular, functions are provided which support file copying and removal. For operations on individual files, see also the os module.\n",
    "\n",
    "- random\n",
    "- torch\n",
    "- os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of classes namely : normal, viral and covid.\n",
    "class_names = ['normal', 'viral', 'covid']\n",
    "\n",
    "#Select the root directory as root_dir    = 'COVID-19 Radiography Database'.\n",
    "root_dir    = 'COVID-19 Radiography Database'\n",
    "\n",
    "#Make a list of source directories named as classes.\n",
    "source_dirs = ['NORMAL', 'Viral Pneumonia', 'COVID-19']\n",
    "\n",
    "#Create a test folder if \"NORMAL\" directory exists.\n",
    "if os.path.isdir(os.path.join(root_dir, source_dirs[1])):    \n",
    "    os.mkdir(os.path.join(root_dir, 'test'))\n",
    "    \n",
    "    #Rename the directory folders as per the class names given.\n",
    "    for i, d in enumerate(source_dirs):\n",
    "        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n",
    "    \n",
    "    #Create the three classes' folders in the test directory\n",
    "    for c in class_names:\n",
    "        os.mkdir(os.path.join(root_dir, 'test', c))\n",
    "    \n",
    "    #Make a list of ALL the images from each class folders exect test.\n",
    "    for c in class_names:\n",
    "        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n",
    "        \n",
    "        #Sample out certain images from each class randomly to create a test dataset \n",
    "        #and move them to test folder by changing their path directory using shutil library.\n",
    "        selected_images = random.sample(images, 30)\n",
    "        for image in selected_images:\n",
    "            source_path = os.path.join(root_dir, c, image)\n",
    "            target_path = os.path.join(root_dir, 'test', c, image)\n",
    "            shutil.move(source_path, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a class: ChestXRayDataset.\n",
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    #Define a constructor to initialize an object instance as self with 2 parameters: image_dirs, transform.\n",
    "    def __init__(self, image_dirs, transform):\n",
    "        \n",
    "        #Inside the __init__ constructor, define a get_images to make a list of images for a given class_name.\n",
    "        def get_images(class_name): #Check if the file is really a \".png\".\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')] \n",
    "            print(f'Found {len(images)} {class_name} examples')\n",
    "            return images\n",
    "        \n",
    "        #Initialize the self.images and self.class_names.\n",
    "        self.images = {}\n",
    "        self.class_names = ['normal', 'viral', 'covid']\n",
    "        \n",
    "        #Call the get_images one by one to report out the number of examples in class for the given dataset.\n",
    "        for c in self.class_names:\n",
    "            self.images[c] = get_images(c)\n",
    "        \n",
    "        #Initialize the self.image_dirs and self.transform with the constructor parameters.\n",
    "        self.image_dirs = image_dirs\n",
    "        self.transform = transform\n",
    "  \n",
    "    #Define __len__ : to return number of images in each class.\n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    \n",
    "    #Define __getitem__ to \n",
    "    def __getitem__(self, index):\n",
    "        class_name = random.choice(self.class_names)\n",
    "        index = index%len(self.images[class_name])\n",
    "        image_name = self.images[class_name][index]\n",
    "        image_path = os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout : https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size = (224, 224)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size = (224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the directories of the training/testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = {\n",
    "    'normal': 'COVID-19 Radiography Database/normal',\n",
    "    'viral': 'COVID-19 Radiography Database/viral',\n",
    "    'covid': 'COVID-19 Radiography Database/covid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1311 normal examples\n",
      "Found 1315 viral examples\n",
      "Found 189 covid examples\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = {\n",
    "    'normal': 'COVID-19 Radiography Database/test/normal',\n",
    "    'viral': 'COVID-19 Radiography Database/test/viral',\n",
    "    'covid': 'COVID-19 Radiography Database/test/covid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 normal examples\n",
      "Found 30 viral examples\n",
      "Found 30 covid examples\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ChestXRayDataset(test_dirs, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches 470\n",
      "Number of test batches 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 6\n",
    "\n",
    "#DataLoader : \n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "print('Number of training batches', len(dl_train))\n",
    "print('Number of test batches', len(dl_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "def show_images(images, labels, preds):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, 6, i + 1, xticks = [], yticks = [])\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "        mean  = np.array([0.485, 0.456, 0.406])\n",
    "        std   = np.array([0.229, 0.224, 0.225])\n",
    "        image = image*std + mean\n",
    "        image = np.clip(image, 0., 1.)\n",
    "        plt.imshow(image)\n",
    "        col   = 'green'\n",
    "        if preds[i] != labels[i]:\n",
    "            col = 'red'\n",
    "            \n",
    "        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
    "        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color = col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dl_train))\n",
    "show_images(images, labels, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dl_test))\n",
    "show_images(images, labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.fc = torch.nn.Linear(in_features = 512, out_features = 3)\n",
    "loss_fn     = torch.nn.CrossEntropyLoss()\n",
    "optimizer   = torch.optim.Adam(resnet18.parameters(), lr = 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds():\n",
    "    resnet18.eval()\n",
    "    images, labels = next(iter(dl_test))\n",
    "    outputs  = resnet18(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    show_images(images, labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    print('Starting training..')\n",
    "    for e in range(0, epochs):\n",
    "        print('='*20)\n",
    "        print(f'Starting epoch {e + 1}/{epochs}')\n",
    "        print('='*20)\n",
    "\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.\n",
    "\n",
    "        resnet18.train() # set model to training phase\n",
    "\n",
    "        for train_step, (images, labels) in enumerate(dl_train):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet18(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            if train_step % 20 == 0:\n",
    "                print('Evaluating at step', train_step)\n",
    "\n",
    "                accuracy = 0\n",
    "\n",
    "                resnet18.eval() # set model to eval phase\n",
    "\n",
    "                for val_step, (images, labels) in enumerate(dl_test):\n",
    "                    outputs = resnet18(images)\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    accuracy += sum((preds == labels).numpy())\n",
    "\n",
    "                val_loss /= (val_step + 1)\n",
    "                accuracy = accuracy/len(test_dataset)\n",
    "                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "                show_preds()\n",
    "\n",
    "                resnet18.train()\n",
    "\n",
    "                if accuracy >= 0.95:\n",
    "                    print('Performance condition satisfied, stopping..')\n",
    "                    return\n",
    "\n",
    "        train_loss /= (train_step + 1)\n",
    "\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "    print('Training complete..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
